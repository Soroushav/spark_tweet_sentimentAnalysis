{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aee266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f25ce37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"tweets\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fce783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('target', IntegerType(), True),\n",
    "    StructField('id', IntegerType(), True),\n",
    "    StructField('date', StringType(), True),\n",
    "    StructField('flag', StringType(), True),\n",
    "    StructField('user', StringType(), True),\n",
    "    StructField('text', StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "565a8856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------------+--------+---------------+--------------------+\n",
      "|target|        id|                date|    flag|           user|                text|\n",
      "+------+----------+--------------------+--------+---------------+--------------------+\n",
      "|     0|1467810369|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|\n",
      "|     0|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|     0|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|     0|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|     0|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "+------+----------+--------------------+--------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"../database\", schema=schema)\n",
    "df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a1e8adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|target|                text|\n",
      "+------+--------------------+\n",
      "|     0|@switchfoot http:...|\n",
      "|     0|is upset that he ...|\n",
      "|     0|@Kenichan I dived...|\n",
      "|     0|my whole body fee...|\n",
      "|     0|@nationwideclass ...|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.select(\"target\", \"text\")\n",
    "df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80bda1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|target| count|\n",
      "+------+------+\n",
      "|     0|800000|\n",
      "|     4|800000|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"target\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24cbcb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "change_target = when(df['target'] == 4, 1).otherwise(df['target'])\n",
    "df = df.withColumn('target', change_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cef23ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|target| count|\n",
      "+------+------+\n",
      "|     0|800000|\n",
      "|     1|800000|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"target\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7ad38f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_values = df.filter(df['text'].isNull()).count()\n",
    "null_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98cd1fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    # Remove URLs, mentions, and hashtags\n",
    "    tweet = re.sub(r'@\\w+|\\w+://\\S+|(#\\S+)', '', tweet)\n",
    "    # Remove non-letters e.g punctuation, numbers\n",
    "    tweet = re.sub(r'[^a-zA-Z\\s]+', '', tweet) \n",
    "    return tweet  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b019bec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|target|                text|\n",
      "+------+--------------------+\n",
      "|     0|   awww thats a b...|\n",
      "|     0|is upset that he ...|\n",
      "|     0| i dived many tim...|\n",
      "|     0|my whole body fee...|\n",
      "|     0| no its not behav...|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "preprocess_udf = udf(preprocess_tweet, StringType())\n",
    "new_df = df.withColumn('text', preprocess_udf(df['text']))\n",
    "new_df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "910278fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Tatiana_K nope they didn't have it \n",
      " nope they didnt have it \n"
     ]
    }
   ],
   "source": [
    "rows = df.select('text').collect()\n",
    "print(rows[8][\"text\"])\n",
    "\n",
    "new_rows = new_df.select('text').collect()\n",
    "print(new_rows[8][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bcc314c-2a0f-4550-9ae6-97a979c87ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk) (1.3.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2025.11.3-cp311-cp311-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m896.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from nltk) (4.66.1)\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m998.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading regex-2025.11.3-cp311-cp311-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (793 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.4/793.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, nltk\n",
      "Successfully installed nltk-3.9.2 regex-2025.11.3\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ef52e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def porterStemmerTweet(tweet):\n",
    "    if tweet is None:\n",
    "        return None\n",
    "    new_tweet = \"\"\n",
    "    for word in tweet.split(\" \"):\n",
    "        new_tweet += ps.stem(word) + \" \"\n",
    "    return new_tweet.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edd942ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|target|                text|\n",
      "+------+--------------------+\n",
      "|     0|   awww thats a b...|\n",
      "|     0|is upset that he ...|\n",
      "|     0| i dived many tim...|\n",
      "|     0|my whole body fee...|\n",
      "|     0| no its not behav...|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae218641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|target|                text|\n",
      "+------+--------------------+\n",
      "|     0|awww that a bumme...|\n",
      "|     0|is upset that he ...|\n",
      "|     0|i dive mani time ...|\n",
      "|     0|my whole bodi fee...|\n",
      "|     0|no it not behav a...|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocess_stem_udf = udf(porterStemmerTweet, StringType())\n",
    "new_df = new_df.withColumn('text', preprocess_stem_udf(new_df['text']))\n",
    "new_df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3147221b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.coalesce(1) \\\n",
    "  .write \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .csv(\"./database/new_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93d87f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f212c4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------+\n",
      "|target|text                                                                                                                 |tokens                                                                                                                                       |filtered_tokens                                                                                             |\n",
      "+------+---------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------+\n",
      "|0     |@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  |[@switchfoot, http://twitpic.com/2y1zl, -, awww,, that's, a, bummer., , you, shoulda, got, david, carr, of, third, day, to, do, it., ;d]     |[@switchfoot, http://twitpic.com/2y1zl, -, awww,, bummer., , shoulda, got, david, carr, third, day, it., ;d]|\n",
      "|0     |is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!      |[is, upset, that, he, can't, update, his, facebook, by, texting, it..., and, might, cry, as, a, result, , school, today, also., blah!]       |[upset, update, facebook, texting, it..., might, cry, result, , school, today, also., blah!]                |\n",
      "|0     |@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds                            |[@kenichan, i, dived, many, times, for, the, ball., managed, to, save, 50%, , the, rest, go, out, of, bounds]                                |[@kenichan, dived, many, times, ball., managed, save, 50%, , rest, go, bounds]                              |\n",
      "|0     |my whole body feels itchy and like its on fire                                                                       |[my, whole, body, feels, itchy, and, like, its, on, fire]                                                                                    |[whole, body, feels, itchy, like, fire]                                                                     |\n",
      "|0     |@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.       |[@nationwideclass, no,, it's, not, behaving, at, all., i'm, mad., why, am, i, here?, because, i, can't, see, you, all, over, there.]         |[@nationwideclass, no,, behaving, all., mad., here?, see, there.]                                           |\n",
      "|0     |@Kwesidei not the whole crew                                                                                         |[@kwesidei, not, the, whole, crew]                                                                                                           |[@kwesidei, whole, crew]                                                                                    |\n",
      "|0     |Need a hug                                                                                                           |[need, a, hug]                                                                                                                               |[need, hug]                                                                                                 |\n",
      "|0     |@LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?                  |[@loltrish, hey, , long, time, no, see!, yes.., rains, a, bit, ,only, a, bit, , lol, ,, i'm, fine, thanks, ,, how's, you, ?]                 |[@loltrish, hey, , long, time, see!, yes.., rains, bit, ,only, bit, , lol, ,, fine, thanks, ,, ?]           |\n",
      "|0     |@Tatiana_K nope they didn't have it                                                                                  |[@tatiana_k, nope, they, didn't, have, it]                                                                                                   |[@tatiana_k, nope]                                                                                          |\n",
      "|0     |@twittera que me muera ?                                                                                             |[@twittera, que, me, muera, ?]                                                                                                               |[@twittera, que, muera, ?]                                                                                  |\n",
      "|0     |spring break in plain city... it's snowing                                                                           |[spring, break, in, plain, city..., it's, snowing]                                                                                           |[spring, break, plain, city..., snowing]                                                                    |\n",
      "|0     |I just re-pierced my ears                                                                                            |[i, just, re-pierced, my, ears]                                                                                                              |[re-pierced, ears]                                                                                          |\n",
      "|0     |@caregiving I couldn't bear to watch it.  And I thought the UA loss was embarrassing . . . . .                       |[@caregiving, i, couldn't, bear, to, watch, it., , and, i, thought, the, ua, loss, was, embarrassing, ., ., ., ., .]                         |[@caregiving, bear, watch, it., , thought, ua, loss, embarrassing, ., ., ., ., .]                           |\n",
      "|0     |@octolinz16 It it counts, idk why I did either. you never talk to me anymore                                         |[@octolinz16, it, it, counts,, idk, why, i, did, either., you, never, talk, to, me, anymore]                                                 |[@octolinz16, counts,, idk, either., never, talk, anymore]                                                  |\n",
      "|0     |@smarrison i would've been the first, but i didn't have a gun.    not really though, zac snyder's just a doucheclown.|[@smarrison, i, would've, been, the, first,, but, i, didn't, have, a, gun., , , , not, really, though,, zac, snyder's, just, a, doucheclown.]|[@smarrison, would've, first,, gun., , , , really, though,, zac, snyder's, doucheclown.]                    |\n",
      "|0     |@iamjazzyfizzle I wish I got to watch it with you!! I miss you and @iamlilnicki  how was the premiere?!              |[@iamjazzyfizzle, i, wish, i, got, to, watch, it, with, you!!, i, miss, you, and, @iamlilnicki, , how, was, the, premiere?!]                 |[@iamjazzyfizzle, wish, got, watch, you!!, miss, @iamlilnicki, , premiere?!]                                |\n",
      "|0     |Hollis' death scene will hurt me severely to watch on film  wry is directors cut not out now?                        |[hollis', death, scene, will, hurt, me, severely, to, watch, on, film, , wry, is, directors, cut, not, out, now?]                            |[hollis', death, scene, hurt, severely, watch, film, , wry, directors, cut, now?]                           |\n",
      "|0     |about to file taxes                                                                                                  |[about, to, file, taxes]                                                                                                                     |[file, taxes]                                                                                               |\n",
      "|0     |@LettyA ahh ive always wanted to see rent  love the soundtrack!!                                                     |[@lettya, ahh, ive, always, wanted, to, see, rent, , love, the, soundtrack!!]                                                                |[@lettya, ahh, ive, always, wanted, see, rent, , love, soundtrack!!]                                        |\n",
      "|0     |@FakerPattyPattz Oh dear. Were you drinking out of the forgotten table drinks?                                       |[@fakerpattypattz, oh, dear., were, you, drinking, out, of, the, forgotten, table, drinks?]                                                  |[@fakerpattypattz, oh, dear., drinking, forgotten, table, drinks?]                                          |\n",
      "+------+---------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered_tokens\")\n",
    "df_tokens = tokenizer.transform(df)\n",
    "# df_tokens.show(truncate=False)\n",
    "\n",
    "df_remover = remover.transform(df_tokens)\n",
    "df_remover.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "165bfa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|target|text                                                                                                                 |tokens                                                                                                                                       |filtered_tokens                                                                                             |raw_features                                                                                                                                          |\n",
      "+------+---------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0     |@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  |[@switchfoot, http://twitpic.com/2y1zl, -, awww,, that's, a, bummer., , you, shoulda, got, david, carr, of, third, day, to, do, it., ;d]     |[@switchfoot, http://twitpic.com/2y1zl, -, awww,, bummer., , shoulda, got, david, carr, third, day, it., ;d]|(16384,[45,3420,3651,4371,4805,5872,8301,9178,12429,12732,12906,13001,13798,15817],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])         |\n",
      "|0     |is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!      |[is, upset, that, he, can't, update, his, facebook, by, texting, it..., and, might, cry, as, a, result, , school, today, also., blah!]       |[upset, update, facebook, texting, it..., might, cry, result, , school, today, also., blah!]                |(16384,[3420,8433,8783,10425,10708,10947,11321,11879,13573,15086,15678,15866,16015],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])            |\n",
      "|0     |@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds                            |[@kenichan, i, dived, many, times, for, the, ball., managed, to, save, 50%, , the, rest, go, out, of, bounds]                                |[@kenichan, dived, many, times, ball., managed, save, 50%, , rest, go, bounds]                              |(16384,[1219,1616,2888,3420,3924,5025,6315,7553,12006,13505,14177,15668],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                           |\n",
      "|0     |my whole body feels itchy and like its on fire                                                                       |[my, whole, body, feels, itchy, and, like, its, on, fire]                                                                                    |[whole, body, feels, itchy, like, fire]                                                                     |(16384,[1353,5607,7175,9879,11650,15171],[1.0,1.0,1.0,1.0,1.0,1.0])                                                                                   |\n",
      "|0     |@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.       |[@nationwideclass, no,, it's, not, behaving, at, all., i'm, mad., why, am, i, here?, because, i, can't, see, you, all, over, there.]         |[@nationwideclass, no,, behaving, all., mad., here?, see, there.]                                           |(16384,[1968,2096,3434,4268,8287,8538,9504,9515],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                   |\n",
      "|0     |@Kwesidei not the whole crew                                                                                         |[@kwesidei, not, the, whole, crew]                                                                                                           |[@kwesidei, whole, crew]                                                                                    |(16384,[1157,7174,15171],[1.0,1.0,1.0])                                                                                                               |\n",
      "|0     |Need a hug                                                                                                           |[need, a, hug]                                                                                                                               |[need, hug]                                                                                                 |(16384,[106,1241],[1.0,1.0])                                                                                                                          |\n",
      "|0     |@LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?                  |[@loltrish, hey, , long, time, no, see!, yes.., rains, a, bit, ,only, a, bit, , lol, ,, i'm, fine, thanks, ,, how's, you, ?]                 |[@loltrish, hey, , long, time, see!, yes.., rains, bit, ,only, bit, , lol, ,, fine, thanks, ,, ?]           |(16384,[191,2035,3420,6693,6829,7008,8527,9041,9173,9704,10259,12604,13003,15206,16153],[1.0,1.0,2.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0])|\n",
      "|0     |@Tatiana_K nope they didn't have it                                                                                  |[@tatiana_k, nope, they, didn't, have, it]                                                                                                   |[@tatiana_k, nope]                                                                                          |(16384,[9533,12034],[1.0,1.0])                                                                                                                        |\n",
      "|0     |@twittera que me muera ?                                                                                             |[@twittera, que, me, muera, ?]                                                                                                               |[@twittera, que, muera, ?]                                                                                  |(16384,[519,2035,3403,11011],[1.0,1.0,1.0,1.0])                                                                                                       |\n",
      "|0     |spring break in plain city... it's snowing                                                                           |[spring, break, in, plain, city..., it's, snowing]                                                                                           |[spring, break, plain, city..., snowing]                                                                    |(16384,[4111,5284,9660,9772,10067],[1.0,1.0,1.0,1.0,1.0])                                                                                             |\n",
      "|0     |I just re-pierced my ears                                                                                            |[i, just, re-pierced, my, ears]                                                                                                              |[re-pierced, ears]                                                                                          |(16384,[853,6534],[1.0,1.0])                                                                                                                          |\n",
      "|0     |@caregiving I couldn't bear to watch it.  And I thought the UA loss was embarrassing . . . . .                       |[@caregiving, i, couldn't, bear, to, watch, it., , and, i, thought, the, ua, loss, was, embarrassing, ., ., ., ., .]                         |[@caregiving, bear, watch, it., , thought, ua, loss, embarrassing, ., ., ., ., .]                           |(16384,[228,3420,6282,8997,11271,12429,12636,13563,14993,16379],[1.0,1.0,1.0,1.0,1.0,1.0,5.0,1.0,1.0,1.0])                                            |\n",
      "|0     |@octolinz16 It it counts, idk why I did either. you never talk to me anymore                                         |[@octolinz16, it, it, counts,, idk, why, i, did, either., you, never, talk, to, me, anymore]                                                 |[@octolinz16, counts,, idk, either., never, talk, anymore]                                                  |(16384,[1181,6062,6589,8192,9255,13835,15369],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                          |\n",
      "|0     |@smarrison i would've been the first, but i didn't have a gun.    not really though, zac snyder's just a doucheclown.|[@smarrison, i, would've, been, the, first,, but, i, didn't, have, a, gun., , , , not, really, though,, zac, snyder's, just, a, doucheclown.]|[@smarrison, would've, first,, gun., , , , really, though,, zac, snyder's, doucheclown.]                    |(16384,[1128,3420,4814,7697,8806,10674,11373,12498,16272,16314],[1.0,3.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                            |\n",
      "|0     |@iamjazzyfizzle I wish I got to watch it with you!! I miss you and @iamlilnicki  how was the premiere?!              |[@iamjazzyfizzle, i, wish, i, got, to, watch, it, with, you!!, i, miss, you, and, @iamlilnicki, , how, was, the, premiere?!]                 |[@iamjazzyfizzle, wish, got, watch, you!!, miss, @iamlilnicki, , premiere?!]                                |(16384,[228,3359,3420,4335,6061,6948,12638,12906,14978],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                        |\n",
      "|0     |Hollis' death scene will hurt me severely to watch on film  wry is directors cut not out now?                        |[hollis', death, scene, will, hurt, me, severely, to, watch, on, film, , wry, is, directors, cut, not, out, now?]                            |[hollis', death, scene, hurt, severely, watch, film, , wry, directors, cut, now?]                           |(16384,[228,907,1086,3420,3702,7293,8161,8186,9348,10424,12658,16222],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                              |\n",
      "|0     |about to file taxes                                                                                                  |[about, to, file, taxes]                                                                                                                     |[file, taxes]                                                                                               |(16384,[5030,13828],[1.0,1.0])                                                                                                                        |\n",
      "|0     |@LettyA ahh ive always wanted to see rent  love the soundtrack!!                                                     |[@lettya, ahh, ive, always, wanted, to, see, rent, , love, the, soundtrack!!]                                                                |[@lettya, ahh, ive, always, wanted, see, rent, , love, soundtrack!!]                                        |(16384,[2696,3319,3420,6256,8538,11048,11614,12273,14243,15450],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                            |\n",
      "|0     |@FakerPattyPattz Oh dear. Were you drinking out of the forgotten table drinks?                                       |[@fakerpattypattz, oh, dear., were, you, drinking, out, of, the, forgotten, table, drinks?]                                                  |[@fakerpattypattz, oh, dear., drinking, forgotten, table, drinks?]                                          |(16384,[1800,5456,7280,10629,14364,15234,16091],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                        |\n",
      "+------+---------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashing_tf = HashingTF(\n",
    "    inputCol=\"filtered_tokens\",\n",
    "    outputCol=\"raw_features\",\n",
    "    numFeatures=2**14  # you can tune this\n",
    ")\n",
    "hashing_df = hashing_tf.transform(df_remover)\n",
    "hashing_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d759df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ba96e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = hashing_df.randomSplit([0.9, 0.1], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c723f1e-96c6-467e-acc4-ab91f6fc493c",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e19527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC(\n",
    "    featuresCol=\"raw_features\",\n",
    "    labelCol=\"target\",\n",
    "    maxIter=200,\n",
    "    regParam=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "065cce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3818ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+------------------------------------------+\n",
      "|target|prediction|rawPrediction                             |\n",
      "+------+----------+------------------------------------------+\n",
      "|0     |1.0       |[-0.03887278397316299,0.03887278397316299]|\n",
      "|0     |0.0       |[0.5376788738983288,-0.5376788738983288]  |\n",
      "|0     |0.0       |[0.431778074163398,-0.431778074163398]    |\n",
      "|0     |0.0       |[1.1223644960518568,-1.1223644960518568]  |\n",
      "|0     |0.0       |[0.12539461613773975,-0.12539461613773975]|\n",
      "|0     |1.0       |[-0.19429277242949577,0.19429277242949577]|\n",
      "|0     |0.0       |[0.5925933948435009,-0.5925933948435009]  |\n",
      "|0     |0.0       |[1.4966230842864516,-1.4966230842864516]  |\n",
      "|0     |0.0       |[3.3830066164279016,-3.3830066164279016]  |\n",
      "|0     |1.0       |[-1.8526332937966976,1.8526332937966976]  |\n",
      "+------+----------+------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test_df)\n",
    "predictions.select(\"target\", \"prediction\", \"rawPrediction\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bd1efbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC (ROC): 0.8208948763298934\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"target\",\n",
    "    rawPredictionCol=\"rawPrediction\",   # default for LinearSVC & LogisticRegression\n",
    "    metricName=\"areaUnderROC\"           # or \"areaUnderPR\"\n",
    ")\n",
    "\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(\"AUC (ROC):\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c1b62d-f0a5-41e2-ac83-78dd6270709f",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0df99d7e-1bcf-49e6-aad2-e014ce795b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol=\"raw_features\", labelCol=\"target\",maxIter=200, regParam=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6351907-955d-42c6-80ca-a1b52e51c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb97c072-5987-4185-8c04-159e820b5d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+------------------------------------------+\n",
      "|target|prediction|rawPrediction                             |\n",
      "+------+----------+------------------------------------------+\n",
      "|0     |0.0       |[0.1757218500903969,-0.1757218500903969]  |\n",
      "|0     |0.0       |[0.8584967906132306,-0.8584967906132306]  |\n",
      "|0     |0.0       |[0.7519899781412592,-0.7519899781412592]  |\n",
      "|0     |0.0       |[1.5040557172354578,-1.5040557172354578]  |\n",
      "|0     |0.0       |[0.2632813565686486,-0.2632813565686486]  |\n",
      "|0     |1.0       |[-0.11458124279981874,0.11458124279981874]|\n",
      "|0     |0.0       |[1.0276917144518487,-1.0276917144518487]  |\n",
      "|0     |0.0       |[2.045554470332043,-2.045554470332043]    |\n",
      "|0     |0.0       |[5.00948751956508,-5.00948751956508]      |\n",
      "|0     |1.0       |[-2.217371040709446,2.217371040709446]    |\n",
      "+------+----------+------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test_df)\n",
    "predictions.select(\"target\", \"prediction\", \"rawPrediction\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e67dbd1-224d-430d-b930-9603f3b22964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC (ROC): 0.8222536026933774\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"target\",\n",
    "    rawPredictionCol=\"rawPrediction\",   # default for LinearSVC & LogisticRegression\n",
    "    metricName=\"areaUnderROC\"           # or \"areaUnderPR\"\n",
    ")\n",
    "\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(\"AUC (ROC):\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad10c557-ae98-48c9-982a-f497ff308fe0",
   "metadata": {},
   "source": [
    "## RandomForrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6918b92-a17a-4e7d-bed4-2325ba114515",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(featuresCol=\"raw_features\", labelCol=\"target\", numTrees=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
