{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aee266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f25ce37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/11/17 18:41:12 WARN Utils: Your hostname, Soroushs-MacBook-Air.local, resolves to a loopback address: 127.0.0.1; using 192.168.1.101 instead (on interface en0)\n",
      "25/11/17 18:41:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/17 18:41:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"tweets\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fce783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('target', IntegerType(), True),\n",
    "    StructField('id', IntegerType(), True),\n",
    "    StructField('date', StringType(), True),\n",
    "    StructField('flag', StringType(), True),\n",
    "    StructField('user', StringType(), True),\n",
    "    StructField('text', StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "565a8856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------------+--------+---------------+--------------------+\n",
      "|target|        id|                date|    flag|           user|                text|\n",
      "+------+----------+--------------------+--------+---------------+--------------------+\n",
      "|     0|1467810369|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|\n",
      "|     0|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|     0|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|     0|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|     0|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "+------+----------+--------------------+--------+---------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"./database\", schema=schema)\n",
    "df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a1e8adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|target|                text|\n",
      "+------+--------------------+\n",
      "|     0|@switchfoot http:...|\n",
      "|     0|is upset that he ...|\n",
      "|     0|@Kenichan I dived...|\n",
      "|     0|my whole body fee...|\n",
      "|     0|@nationwideclass ...|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df = df.select(\"target\", \"text\")\n",
    "df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80bda1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|target| count|\n",
      "+------+------+\n",
      "|     0|800000|\n",
      "|     4|800000|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"target\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24cbcb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "change_target = when(df['target'] == 4, 1).otherwise(df['target'])\n",
    "df = df.withColumn('target', change_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cef23ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|target| count|\n",
      "+------+------+\n",
      "|     0|800000|\n",
      "|     1|800000|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"target\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7ad38f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_values = df.filter(df['text'].isNull()).count()\n",
    "null_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98cd1fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    # Remove URLs, mentions, and hashtags\n",
    "    tweet = re.sub(r'@\\w+|\\w+://\\S+|(#\\S+)', '', tweet)\n",
    "    # Remove non-letters e.g punctuation, numbers\n",
    "    tweet = re.sub(r'[^a-zA-Z\\s]+', '', tweet) \n",
    "    return tweet  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b019bec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|target|                text|\n",
      "+------+--------------------+\n",
      "|     0|   awww thats a b...|\n",
      "|     0|is upset that he ...|\n",
      "|     0| i dived many tim...|\n",
      "|     0|my whole body fee...|\n",
      "|     0| no its not behav...|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "preprocess_udf = udf(preprocess_tweet, StringType())\n",
    "new_df = df.withColumn('text', preprocess_udf(df['text']))\n",
    "new_df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "910278fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Tatiana_K nope they didn't have it \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nope they didnt have it \n"
     ]
    }
   ],
   "source": [
    "rows = df.select('text').collect()\n",
    "print(rows[8][\"text\"])\n",
    "\n",
    "new_rows = new_df.select('text').collect()\n",
    "print(new_rows[8][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ef52e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def porterStemmerTweet(tweet):\n",
    "    if tweet is None:\n",
    "        return None\n",
    "    new_tweet = \"\"\n",
    "    for word in tweet.split(\" \"):\n",
    "        new_tweet += ps.stem(word) + \" \"\n",
    "    return new_tweet.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edd942ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|target|                text|\n",
      "+------+--------------------+\n",
      "|     0|   awww thats a b...|\n",
      "|     0|is upset that he ...|\n",
      "|     0| i dived many tim...|\n",
      "|     0|my whole body fee...|\n",
      "|     0| no its not behav...|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "new_df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae218641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|target|                text|\n",
      "+------+--------------------+\n",
      "|     0|awww that a bumme...|\n",
      "|     0|is upset that he ...|\n",
      "|     0|i dive mani time ...|\n",
      "|     0|my whole bodi fee...|\n",
      "|     0|no it not behav a...|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "preprocess_stem_udf = udf(porterStemmerTweet, StringType())\n",
    "new_df = new_df.withColumn('text', preprocess_stem_udf(new_df['text']))\n",
    "new_df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93d87f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f212c4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------+\n",
      "|target|text                                                                                                                 |tokens                                                                                                                                       |filtered_tokens                                                                                             |\n",
      "+------+---------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------+\n",
      "|0     |@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  |[@switchfoot, http://twitpic.com/2y1zl, -, awww,, that's, a, bummer., , you, shoulda, got, david, carr, of, third, day, to, do, it., ;d]     |[@switchfoot, http://twitpic.com/2y1zl, -, awww,, bummer., , shoulda, got, david, carr, third, day, it., ;d]|\n",
      "|0     |is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!      |[is, upset, that, he, can't, update, his, facebook, by, texting, it..., and, might, cry, as, a, result, , school, today, also., blah!]       |[upset, update, facebook, texting, it..., might, cry, result, , school, today, also., blah!]                |\n",
      "|0     |@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds                            |[@kenichan, i, dived, many, times, for, the, ball., managed, to, save, 50%, , the, rest, go, out, of, bounds]                                |[@kenichan, dived, many, times, ball., managed, save, 50%, , rest, go, bounds]                              |\n",
      "|0     |my whole body feels itchy and like its on fire                                                                       |[my, whole, body, feels, itchy, and, like, its, on, fire]                                                                                    |[whole, body, feels, itchy, like, fire]                                                                     |\n",
      "|0     |@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.       |[@nationwideclass, no,, it's, not, behaving, at, all., i'm, mad., why, am, i, here?, because, i, can't, see, you, all, over, there.]         |[@nationwideclass, no,, behaving, all., mad., here?, see, there.]                                           |\n",
      "|0     |@Kwesidei not the whole crew                                                                                         |[@kwesidei, not, the, whole, crew]                                                                                                           |[@kwesidei, whole, crew]                                                                                    |\n",
      "|0     |Need a hug                                                                                                           |[need, a, hug]                                                                                                                               |[need, hug]                                                                                                 |\n",
      "|0     |@LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?                  |[@loltrish, hey, , long, time, no, see!, yes.., rains, a, bit, ,only, a, bit, , lol, ,, i'm, fine, thanks, ,, how's, you, ?]                 |[@loltrish, hey, , long, time, see!, yes.., rains, bit, ,only, bit, , lol, ,, fine, thanks, ,, ?]           |\n",
      "|0     |@Tatiana_K nope they didn't have it                                                                                  |[@tatiana_k, nope, they, didn't, have, it]                                                                                                   |[@tatiana_k, nope]                                                                                          |\n",
      "|0     |@twittera que me muera ?                                                                                             |[@twittera, que, me, muera, ?]                                                                                                               |[@twittera, que, muera, ?]                                                                                  |\n",
      "|0     |spring break in plain city... it's snowing                                                                           |[spring, break, in, plain, city..., it's, snowing]                                                                                           |[spring, break, plain, city..., snowing]                                                                    |\n",
      "|0     |I just re-pierced my ears                                                                                            |[i, just, re-pierced, my, ears]                                                                                                              |[re-pierced, ears]                                                                                          |\n",
      "|0     |@caregiving I couldn't bear to watch it.  And I thought the UA loss was embarrassing . . . . .                       |[@caregiving, i, couldn't, bear, to, watch, it., , and, i, thought, the, ua, loss, was, embarrassing, ., ., ., ., .]                         |[@caregiving, bear, watch, it., , thought, ua, loss, embarrassing, ., ., ., ., .]                           |\n",
      "|0     |@octolinz16 It it counts, idk why I did either. you never talk to me anymore                                         |[@octolinz16, it, it, counts,, idk, why, i, did, either., you, never, talk, to, me, anymore]                                                 |[@octolinz16, counts,, idk, either., never, talk, anymore]                                                  |\n",
      "|0     |@smarrison i would've been the first, but i didn't have a gun.    not really though, zac snyder's just a doucheclown.|[@smarrison, i, would've, been, the, first,, but, i, didn't, have, a, gun., , , , not, really, though,, zac, snyder's, just, a, doucheclown.]|[@smarrison, would've, first,, gun., , , , really, though,, zac, snyder's, doucheclown.]                    |\n",
      "|0     |@iamjazzyfizzle I wish I got to watch it with you!! I miss you and @iamlilnicki  how was the premiere?!              |[@iamjazzyfizzle, i, wish, i, got, to, watch, it, with, you!!, i, miss, you, and, @iamlilnicki, , how, was, the, premiere?!]                 |[@iamjazzyfizzle, wish, got, watch, you!!, miss, @iamlilnicki, , premiere?!]                                |\n",
      "|0     |Hollis' death scene will hurt me severely to watch on film  wry is directors cut not out now?                        |[hollis', death, scene, will, hurt, me, severely, to, watch, on, film, , wry, is, directors, cut, not, out, now?]                            |[hollis', death, scene, hurt, severely, watch, film, , wry, directors, cut, now?]                           |\n",
      "|0     |about to file taxes                                                                                                  |[about, to, file, taxes]                                                                                                                     |[file, taxes]                                                                                               |\n",
      "|0     |@LettyA ahh ive always wanted to see rent  love the soundtrack!!                                                     |[@lettya, ahh, ive, always, wanted, to, see, rent, , love, the, soundtrack!!]                                                                |[@lettya, ahh, ive, always, wanted, see, rent, , love, soundtrack!!]                                        |\n",
      "|0     |@FakerPattyPattz Oh dear. Were you drinking out of the forgotten table drinks?                                       |[@fakerpattypattz, oh, dear., were, you, drinking, out, of, the, forgotten, table, drinks?]                                                  |[@fakerpattypattz, oh, dear., drinking, forgotten, table, drinks?]                                          |\n",
      "+------+---------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered_tokens\")\n",
    "df_tokens = tokenizer.transform(df)\n",
    "# df_tokens.show(truncate=False)\n",
    "\n",
    "df_remover = remover.transform(df_tokens)\n",
    "df_remover.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "165bfa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+--------------------+\n",
      "|target|                text|              tokens|     filtered_tokens|        raw_features|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+\n",
      "|     0|@switchfoot http:...|[@switchfoot, htt...|[@switchfoot, htt...|(16384,[45,3420,3...|\n",
      "|     0|is upset that he ...|[is, upset, that,...|[upset, update, f...|(16384,[3420,8433...|\n",
      "|     0|@Kenichan I dived...|[@kenichan, i, di...|[@kenichan, dived...|(16384,[1219,1616...|\n",
      "|     0|my whole body fee...|[my, whole, body,...|[whole, body, fee...|(16384,[1353,5607...|\n",
      "|     0|@nationwideclass ...|[@nationwideclass...|[@nationwideclass...|(16384,[1968,2096...|\n",
      "|     0|@Kwesidei not the...|[@kwesidei, not, ...|[@kwesidei, whole...|(16384,[1157,7174...|\n",
      "|     0|         Need a hug |      [need, a, hug]|         [need, hug]|(16384,[106,1241]...|\n",
      "|     0|@LOLTrish hey  lo...|[@loltrish, hey, ...|[@loltrish, hey, ...|(16384,[191,2035,...|\n",
      "|     0|@Tatiana_K nope t...|[@tatiana_k, nope...|  [@tatiana_k, nope]|(16384,[9533,1203...|\n",
      "|     0|@twittera que me ...|[@twittera, que, ...|[@twittera, que, ...|(16384,[519,2035,...|\n",
      "|     0|spring break in p...|[spring, break, i...|[spring, break, p...|(16384,[4111,5284...|\n",
      "|     0|I just re-pierced...|[i, just, re-pier...|  [re-pierced, ears]|(16384,[853,6534]...|\n",
      "|     0|@caregiving I cou...|[@caregiving, i, ...|[@caregiving, bea...|(16384,[228,3420,...|\n",
      "|     0|@octolinz16 It it...|[@octolinz16, it,...|[@octolinz16, cou...|(16384,[1181,6062...|\n",
      "|     0|@smarrison i woul...|[@smarrison, i, w...|[@smarrison, woul...|(16384,[1128,3420...|\n",
      "|     0|@iamjazzyfizzle I...|[@iamjazzyfizzle,...|[@iamjazzyfizzle,...|(16384,[228,3359,...|\n",
      "|     0|Hollis' death sce...|[hollis', death, ...|[hollis', death, ...|(16384,[228,907,1...|\n",
      "|     0|about to file taxes |[about, to, file,...|       [file, taxes]|(16384,[5030,1382...|\n",
      "|     0|@LettyA ahh ive a...|[@lettya, ahh, iv...|[@lettya, ahh, iv...|(16384,[2696,3319...|\n",
      "|     0|@FakerPattyPattz ...|[@fakerpattypattz...|[@fakerpattypattz...|(16384,[1800,5456...|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "hashing_tf = HashingTF(\n",
    "    inputCol=\"filtered_tokens\",\n",
    "    outputCol=\"raw_features\",\n",
    "    numFeatures=2**14  # you can tune this\n",
    ")\n",
    "hashing_df = hashing_tf.transform(df_remover)\n",
    "hashing_df.show(truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d759df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ba96e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = hashing_df.randomSplit([0.9, 0.1], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e19527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC(\n",
    "    featuresCol=\"raw_features\",\n",
    "    labelCol=\"target\",\n",
    "    maxIter=50,\n",
    "    regParam=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "065cce8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/17 18:41:51 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = svm.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3818ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 228:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------------------------------------+\n",
      "|target|prediction|rawPrediction                               |\n",
      "+------+----------+--------------------------------------------+\n",
      "|0     |1.0       |[-0.038868793497977144,0.038868793497977144]|\n",
      "|0     |0.0       |[0.5376943153814804,-0.5376943153814804]    |\n",
      "|0     |0.0       |[0.4315355477161895,-0.4315355477161895]    |\n",
      "|0     |0.0       |[1.1223282742957263,-1.1223282742957263]    |\n",
      "|0     |0.0       |[0.12540390495921547,-0.12540390495921547]  |\n",
      "|0     |1.0       |[-0.19429563959469032,0.19429563959469032]  |\n",
      "|0     |0.0       |[0.5926172025433687,-0.5926172025433687]    |\n",
      "|0     |0.0       |[1.4963414355729696,-1.4963414355729696]    |\n",
      "|0     |0.0       |[3.3829374587804013,-3.3829374587804013]    |\n",
      "|0     |1.0       |[-1.8526520991722015,1.8526520991722015]    |\n",
      "+------+----------+--------------------------------------------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test_df)\n",
    "predictions.select(\"target\", \"prediction\", \"rawPrediction\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bd1efbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC (ROC): 0.8208923795196732\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"target\",\n",
    "    rawPredictionCol=\"rawPrediction\",   # default for LinearSVC & LogisticRegression\n",
    "    metricName=\"areaUnderROC\"           # or \"areaUnderPR\"\n",
    ")\n",
    "\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(\"AUC (ROC):\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6925ba26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
